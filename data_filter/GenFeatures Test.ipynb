{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the speedup\n",
    "### Extracting District Names into 9 Dictionaries\n",
    "Because there are only nine different scene locations in the downloaded dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if it was way more than 9, then could have sorted the file names first, then only the change of scene location, construct a new dictionary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import ogr, osr, gdal\n",
    "\n",
    "import fiona\n",
    "from shapely.geometry import Point, shape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change this for Win7,macOS\n",
    "bases = \"C:\\Users\\deepak\\Desktop\\Repo\\Maps\\Districts\\Census\\Dist.shp\"\n",
    "# base_ = \"/Users/macbook/Documents/BTP/Satellite/Data/Maps/Districts/Census_2011\"\n",
    "fc = fiona.open(bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_geocode(pt):\n",
    "    for feature in fc:\n",
    "        if shape(feature['geometry']).contains(pt):\n",
    "            return feature['properties']['DISTRICT']\n",
    "    return \"NRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base2 = \"G:\\BTP\\Satellite\\Data\\Test\"  # Win7\n",
    "base = \"G:\\BTP\\Satellite\\Data\\Test2\"  # Win7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(filename, force=False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    if os.path.isdir(os.path.join(base,root)) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print('%s already present - Skipping extraction of %s' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s' % root)\n",
    "        tar = tarfile.open(os.path.join(base,filename))\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(os.path.join(base,root))\n",
    "        tar.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE07_L1GT_146039_20050702_20170115_01_T2 already present - Skipping extraction of LE07_L1GT_146039_20050702_20170115_01_T2.tar.gz\n",
      "LE07_L1GT_146040_20040512_20170120_01_T2 already present - Skipping extraction of LE07_L1GT_146040_20040512_20170120_01_T2.tar.gz\n",
      "LE07_L1GT_146041_20041222_20170117_01_T2 already present - Skipping extraction of LE07_L1GT_146041_20041222_20170117_01_T2.tar.gz\n",
      "LE07_L1GT_147039_20050725_20170114_01_T2 already present - Skipping extraction of LE07_L1GT_147039_20050725_20170114_01_T2.tar.gz\n",
      "LE07_L1GT_147040_20050506_20170116_01_T2 already present - Skipping extraction of LE07_L1GT_147040_20050506_20170116_01_T2.tar.gz\n",
      "LE07_L1GT_147041_20040807_20170119_01_T2 already present - Skipping extraction of LE07_L1GT_147041_20040807_20170119_01_T2.tar.gz\n",
      "LE07_L1GT_148039_20050918_20170113_01_T2 already present - Skipping extraction of LE07_L1GT_148039_20050918_20170113_01_T2.tar.gz\n",
      "LE07_L1GT_148040_20040627_20170120_01_T2 already present - Skipping extraction of LE07_L1GT_148040_20040627_20170120_01_T2.tar.gz\n",
      "LE07_L1GT_149039_20050128_20170117_01_T2 already present - Skipping extraction of LE07_L1GT_149039_20050128_20170117_01_T2.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# extracting for Test2\n",
    "for directory, subdirList, fileList in os.walk(base):\n",
    "    for filename in fileList:\n",
    "        if filename.endswith(\".tar.gz\"): \n",
    "            d = extract(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directories = [os.path.join(base, d) for d in sorted(os.listdir(base)) if os.path.isdir(os.path.join(base, d))]\n",
    "# print directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = gdal.Open(base2 + \"\\LE07_L1TP_146039_20101223_20161211_01_T1\\LE07_L1TP_146039_20101223_20161211_01_T1_B1.TIF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "osgeo.gdal.Dataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare one `ds` variable here itself, for the transformation of the coordinate system below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the new coordinate system\n",
    "wgs84_wkt = \"\"\"\n",
    "GEOGCS[\"WGS 84\",\n",
    "    DATUM[\"WGS_1984\",\n",
    "        SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
    "            AUTHORITY[\"EPSG\",\"7030\"]],\n",
    "        AUTHORITY[\"EPSG\",\"6326\"]],\n",
    "    PRIMEM[\"Greenwich\",0,\n",
    "        AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "    UNIT[\"degree\",0.01745329251994328,\n",
    "        AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "    AUTHORITY[\"EPSG\",\"4326\"]]\"\"\"\n",
    "new_cs = osr.SpatialReference()\n",
    "new_cs.ImportFromWkt(wgs84_wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(dsx):\n",
    "    old_cs= osr.SpatialReference()\n",
    "    old_cs.ImportFromWkt(dsx.GetProjectionRef())\n",
    "    trs = osr.CoordinateTransformation(old_cs,new_cs) \n",
    "    return trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pixel2coord(x, y, xoff, a, b, yoff, d, e):\n",
    "    \"\"\"Returns global coordinates from coordinates x,y of the pixel\"\"\"\n",
    "    xp = a * x + b * y + xoff\n",
    "    yp = d * x + e * y + yoff\n",
    "    return(xp, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicts = [[],[],[],[],[],[],[],[],[]]\n",
    "dictr = [(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0)]\n",
    "dicti = {\"146039\":0, \"146040\":1, \"146041\":2, \"147039\":3, \"147040\":4, \"147041\":5, \"148039\":6, \"148040\":7, \"149039\":8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_146039_20050702_20170115_01_T2\\LE07_L1GT_146039_20050702_20170115_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_146040_20040512_20170120_01_T2\\LE07_L1GT_146040_20040512_20170120_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_146041_20041222_20170117_01_T2\\LE07_L1GT_146041_20041222_20170117_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_147039_20050725_20170114_01_T2\\LE07_L1GT_147039_20050725_20170114_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_147040_20050506_20170116_01_T2\\LE07_L1GT_147040_20050506_20170116_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_147041_20040807_20170119_01_T2\\LE07_L1GT_147041_20040807_20170119_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_148039_20050918_20170113_01_T2\\LE07_L1GT_148039_20050918_20170113_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_148040_20040627_20170120_01_T2\\LE07_L1GT_148040_20040627_20170120_01_T2_B1.TIF\n",
      "G:\\BTP\\Satellite\\Data\\Test2\\LE07_L1GT_149039_20050128_20170117_01_T2\\LE07_L1GT_149039_20050128_20170117_01_T2_B1.TIF\n",
      "22027.7967823\n",
      "Seconds\n"
     ]
    }
   ],
   "source": [
    "stx = timeit.default_timer()\n",
    "\n",
    "for directory in directories:\n",
    "    \n",
    "    \"\"\" Identifying Month, Year, Spacecraft ID \"\"\"\n",
    "    date = directory.split('\\\\')[-1].split('_')[3] # Change for Win7\n",
    "    satx = directory.split('\\\\')[-1][3]\n",
    "    month = date[4:6]\n",
    "    year = date[0:4]\n",
    "    \n",
    "    scene = directory.split('\\\\')[-1].split('_')[2]\n",
    "    index = dicti[scene]\n",
    "    \n",
    "    #if index != 1: continue\n",
    "    \n",
    "    \"\"\" Visiting every GeoTIFF file \"\"\" \n",
    "    for _,_,files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            \n",
    "            if filename.endswith(\".TIF\"):\n",
    "                \n",
    "                if filename[-5] == '2': break\n",
    "                \n",
    "                print os.path.join(directory,filename)\n",
    "                \n",
    "                ds = gdal.Open(os.path.join(directory,filename))\n",
    "                if ds == None: continue\n",
    "                col, row, _ = ds.RasterXSize, ds.RasterYSize, ds.RasterCount\n",
    "                xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
    "                #--------------------\n",
    "                transform = func(ds)\n",
    "                #--------------------\n",
    "                \n",
    "                dictr[index] = (col,row)\n",
    "                \n",
    "                \"\"\" Now go to each pixel, find its lat,lon. Hence its district, and the pixel value \"\"\"\n",
    "                for i in range(0,col,col/k):\n",
    "                    for j in range(0,row,row/k):\n",
    "                        \n",
    "                        ########### fetching the lat and lon coordinates \n",
    "                        x,y = pixel2coord(i, j, xoff, a, b, yoff, d, e)\n",
    "                        lonx, latx, z = transform.TransformPoint(x,y)\n",
    "                        \n",
    "                        \n",
    "                        ########### fetching the name of district\n",
    "                        \n",
    "                        point = Point(lonx,latx)\n",
    "                        district = reverse_geocode(point)\n",
    "                        \n",
    "                        dicts[index].append(district)\n",
    "                        \n",
    "#                         #----------------------------------------------------------\n",
    "#                         if filename[-5] == '1':\n",
    "#                             point = Point(lonx,latx)\n",
    "#                             district = reverse_geocode(point)\n",
    "#                             dicts[i][str(lonx)+str(latx)] = district\n",
    "#                         else:\n",
    "#                             print \"-------------------- !!!!!!! -------------------\"\n",
    "#                             district = dictx[str(lonx)+str(latx)]\n",
    "#                         #----------------------------------------------------------\n",
    "                        \n",
    "            \n",
    "                            \n",
    "elapsed = timeit.default_timer() - stx\n",
    "print (elapsed)\n",
    "print \"Seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7981, 7271), (7741, 7001), (7761, 7021), (7811, 7051), (7801, 7071), (7821, 7051), (7871, 7111), (7861, 7131), (7941, 7181)]\n"
     ]
    }
   ],
   "source": [
    "print dictr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.3540173718\n",
      "74.8772487691\n",
      "Hanumangarh\n"
     ]
    }
   ],
   "source": [
    "print latx\n",
    "print lonx\n",
    "print district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n",
      "2601\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print len(dicts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = \"G:\\BTP\\Satellite\\Data\\Bulk\\Landsat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base = \"G:\\BTP\\Satellite\\Data\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directories = [os.path.join(base, d) for d in sorted(os.listdir(base)) if os.path.isdir(os.path.join(base, d))]\n",
    "# print directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>ind_district</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Value</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>chandigarh</td>\n",
       "      <td>2004</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>80</td>\n",
       "      <td>400.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>chandigarh</td>\n",
       "      <td>2005</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>50</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>chandigarh</td>\n",
       "      <td>2006</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>50</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>chandigarh</td>\n",
       "      <td>2007</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>50</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>chandigarh</td>\n",
       "      <td>2008</td>\n",
       "      <td>kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_Name ind_district  Crop_Year  Season  Crop  Area  Production  Value  \\\n",
       "0  Chandigarh   chandigarh       2004  kharif  Rice    80       400.0    5.0   \n",
       "1  Chandigarh   chandigarh       2005  kharif  Rice    50       250.0    5.0   \n",
       "2  Chandigarh   chandigarh       2006  kharif  Rice    50       250.0    5.0   \n",
       "3  Chandigarh   chandigarh       2007  kharif  Rice    50       250.0    5.0   \n",
       "4  Chandigarh   chandigarh       2008  kharif  Rice    20       100.0    5.0   \n",
       "\n",
       "      X1     X2  \n",
       "0  500.0  700.0  \n",
       "1  400.0  500.0  \n",
       "2  250.0  400.0  \n",
       "3  250.0  250.0  \n",
       "4  250.0  250.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ricep = pd.read_csv(\"C:\\Users\\deepak\\Desktop\\Repo\\BTP\\Satellite\\Ricep_large.csv\")\n",
    "ricep = ricep.drop([\"Unnamed: 0\"],axis=1)\n",
    "ricep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.empty((ricep.shape[0],1))*np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 'features' contain collumn indexes for the new features \"\"\"\n",
    "\"\"\" 'dictn' is the dictionary mapping name of collumn index to the index number \"\"\"\n",
    "features = []\n",
    "dictn = {}\n",
    "k = 10\n",
    "for i in range(1,13):\n",
    "    for j in range(1,11):\n",
    "        s = str(i) + \"_B\" + str(j) + \"_\"\n",
    "        features.append(s+\"M\")\n",
    "        features.append(s+\"V\")\n",
    "        dictn[s+\"M\"] = k\n",
    "        dictn[s+\"V\"] = k+1\n",
    "        k = k+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    for j in range(1,11):\n",
    "        s = str(i) + \"_B\" + str(j) + \"_\"\n",
    "        features.append(s+\"Mn\")\n",
    "        features.append(s+\"Vn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(index=range(ricep.shape[0]),columns=features)\n",
    "ricex = pd.concat([ricep,tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39356.627305\n",
      "Seconds\n"
     ]
    }
   ],
   "source": [
    "stx = timeit.default_timer()\n",
    "\n",
    "for directory in directories:\n",
    "    \n",
    "#     if bx: continue\n",
    "#     else: bx = True\n",
    "    \n",
    "    \"\"\" Identifying Month, Year, Spacecraft ID \"\"\"\n",
    "    date = directory.split('\\\\')[-1].split('_')[3] # Change for Win7\n",
    "    satx = directory.split('\\\\')[-1][3]\n",
    "    month = date[4:6]\n",
    "    year = date[0:4]\n",
    "    \n",
    "    scene = directory.split('\\\\')[-1].split('_')[2]\n",
    "    index = dicti[scene]\n",
    "    \n",
    "    \"\"\" Visiting every GeoTIFF file \"\"\" \n",
    "    for _,_,files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            \n",
    "            \n",
    "            if filename.endswith(\".TIF\"):\n",
    "                \n",
    "                if filename[-5] == '8': continue\n",
    "                        \n",
    "                ds = gdal.Open(os.path.join(directory,filename))\n",
    "                if ds == None: continue\n",
    "                col, row, _ = ds.RasterXSize, ds.RasterYSize, ds.RasterCount\n",
    "                xoff, a, b, yoff, d, e = ds.GetGeoTransform()\n",
    "                \n",
    "                ind = -1\n",
    "                for i in range(0,col,col/k):\n",
    "                    for j in range(0,row,row/k):\n",
    "                        \n",
    "                        ind += 1\n",
    "                        if ind>2600: break\n",
    "                            \n",
    "                        ########### fetching the lat and lon coordinates \n",
    "                        \n",
    "                        ########### fetching the name of district\n",
    "                        district = dicts[index][ind]\n",
    "                        \n",
    "                        if district == \"NRI\": continue\n",
    "                        \n",
    "                        ########### Locating the row in DataFrame which we want to update\n",
    "                        district = district.lower()\n",
    "                        district = district.strip()\n",
    "                        r = ricex.index[(ricex['ind_district'] == district) & (ricex['Crop_Year'] == int(year))].tolist()\n",
    "                        \n",
    "                        \n",
    "                        if len(r) == 1:\n",
    "                            \n",
    "                            ########### The pixel value for that location\n",
    "                            px,py = i,j\n",
    "                            pix = ds.ReadAsArray(px,py,1,1)\n",
    "                            pix = int(pix[0][0])\n",
    "                            \n",
    "                            \"\"\" Found the row, so now ..\"\"\"\n",
    "                            \"\"\" Find Collumn index corresponding to Month, Band \"\"\"\n",
    "                            ####### Band Number ########\n",
    "                            band = filename.split(\"\\\\\")[-1].split(\"_\")[7:][0].split(\".\")[0][1]\n",
    "                            bnd = band\n",
    "                            if band == '6':\n",
    "                                if filename.split(\"\\\\\")[-1].split(\"_\")[7:][2][0] == '1':\n",
    "                                    bnd = band\n",
    "                                else:\n",
    "                                    bnd = '9'\n",
    "                            elif band == 'Q':\n",
    "                                bnd = '10'\n",
    "                                \n",
    "                                \n",
    "                            if month[0] == '0': \n",
    "                                month = month[1]\n",
    "                                \n",
    "                            sm = month + \"_B\" + bnd +\"_M\"\n",
    "                            \n",
    "                            cm = dictn[sm]\n",
    "                            \n",
    "                            r = r[0]\n",
    "                            # cm is the collumn indexe for mean\n",
    "                            # r[0] is the row index\n",
    "                            \n",
    "                            \n",
    "                            ##### Checking if values are null ...\n",
    "                            valm = ricex.iloc[r,cm]\n",
    "                            if pd.isnull(valm): \n",
    "                                \n",
    "                                ricex.iloc[r,cm] = int(pix)\n",
    "                                ricex.iloc[r,cm+1] = int(pix*pix)\n",
    "                                ricex.iloc[r,cm+240] = 1\n",
    "                                \n",
    "                                continue\n",
    "                                \n",
    "                                \n",
    "                            ##### if the values are not null ...\n",
    "                            valv = int(ricex.iloc[r,cm+1])\n",
    "                            n = int(ricex.iloc[r,cm+240])\n",
    "                            n = n+1\n",
    "                            \n",
    "                            \n",
    "                            # Mean & Variance update\n",
    "                            ricex.iloc[r,cm] = valm + (pix-valm)/n\n",
    "                            ricex.iloc[r,cm+1] = ((n-2)/(n-1))*valv + (pix-valm)*(pix-valm)/n\n",
    "                            ricex.iloc[r,cm+240] = n\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "elapsed = timeit.default_timer() - stx\n",
    "print (elapsed)\n",
    "print \"Seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ricex.to_csv(\"Ricex_prepared.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
